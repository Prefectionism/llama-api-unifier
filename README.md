
# LLM Unified API Project

The newly refactored "llama-api-unifier" project, previously known as "llama" is an open-source platform that assists you in building and deploying applications on LLM at a massive scale using a unified API.

## What is it exactly?

![Logo](docs/icon.png)

This project provides seamless integration with various LLM providers, which include but are not limited to: OpenAI Platform, Azure OpenAI Service, Anthropic, Ollama, LLAMA.CPP, WHISPER.CPP, Hugging Face, Mimic 3, Coqui, LangChain / LangServe, and more. It also offers compatibility with numerous vector databases/indexes like Chroma, Weaviate, In-Memory, and OpenSearch/Elasticsearch.

Moreover, it facilitates various types of extractors such as Text, Code, Tesseract, Unstructured. It also supports LLM Classifiers for smart data segregation.

For detailed configuration guides of all these features, please refer to the provided markdowns.

## Use Cases

### Retrieval Augmented Generation (RAG)

Refer to the provided markdown to configure RAG.

Also provided are guides on how to index documents using an extractor and direct JSON documents.

### Hermes Function Calling

To use Hermes function calling, refer to the guide given below. Note that the guide assumes you have a localhost server running Llama on port 9081.

## Conclusion

The new owner "Prefectionism" is pleased to maintain and continue the development of this useful open-source llama project. Considering its massive scaling potential and wide-ranging integration, it is hoped it will prove invaluable to developers in need of LLM services.

This project is open to improvements. If you have feature requests, bug reports, or wish to contribute to the code, feel free to raise an issue or submit a pull request. Happy coding!
